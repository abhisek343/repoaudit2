# Backend Environment Configuration
# Copy this file to .env and configure your API keys

# GitHub Token (optional, but recommended for higher rate limits)
GITHUB_TOKEN=ghp_your_github_personal_access_token_here

# LLM Configuration (choose one)
OPENAI_API_KEY=sk-your-openai-api-key-here
# OR
GEMINI_API_KEY=your-gemini-api-key-here  
# OR
CLAUDE_API_KEY=your-claude-api-key-here

# Optional: Adjust analysis limits
RATE_LIMIT_DELAY_MS=1000
LLM_VULN_DELAY_MS=2000
PERF_METRICS_FILE_LIMIT=5
TECH_DEBT_FILE_LIMIT=5
API_ENDPOINT_FILE_LIMIT=5
LLM_DIAGRAM_TIMEOUT_MS=15000

# Server Configuration
PORT=3001
NODE_ENV=development

# Analysis Configuration
MAX_FILE_SIZE_MB=50
MAX_TOTAL_SIZE_MB=500
ANALYSIS_TIMEOUT_MINUTES=30

# Security
ENABLE_HELMET=true
CORS_ORIGIN=http://localhost:5173
